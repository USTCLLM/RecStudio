backbone: 
  interest: 
    class: BPR
    loss_reduction: none

  conformity: 
    class: BPR
    loss_reduction: none

train:
  discrepancy: l1
  dis_penalty: 0.01

  int_weight: 0.1
  con_weight: 0.1
  loss_decay: 0.9
  learning_rate: 1e-3

data:
  neg_count: 2
  margin_up: 40
  margin_down: 40
  pool: 40
  adaptive: True
  margin_decay: 0.9